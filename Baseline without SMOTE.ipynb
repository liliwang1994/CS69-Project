{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTRU2 Dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python27\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "d:\\python27\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:122: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Finally-------------------------\n",
      "bn\n",
      "The AUC is 0.764 \n",
      "The recall is 0.005 \n",
      "The p is nan \n",
      "The F1 is 0.008 \n",
      "knn\n",
      "The AUC is 0.936 \n",
      "The recall is 0.791 \n",
      "The p is 0.894 \n",
      "The F1 is 0.838 \n",
      "lr\n",
      "The AUC is 0.975 \n",
      "The recall is 0.819 \n",
      "The p is 0.940 \n",
      "The F1 is 0.874 \n",
      "gb\n",
      "The AUC is 0.958 \n",
      "The recall is 0.841 \n",
      "The p is 0.678 \n",
      "The F1 is 0.745 \n",
      "randomforest\n",
      "The AUC is 0.958 \n",
      "The recall is 0.822 \n",
      "The p is 0.926 \n",
      "The F1 is 0.871 \n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.metrics import silhouette_score\n",
    "import sys\n",
    "sys.path.append('/dartfs-hpc/rc/home/t/f00355t/imbalance')\n",
    "from imblearn.over_sampling import SMOTE\n",
    "np.set_printoptions(threshold='nan')\n",
    "tmp = np.loadtxt(\"HTRU_2.csv\", dtype=np.str,skiprows=1, delimiter=\",\")\n",
    "total_data=tmp[0:,0:tmp.shape[1]-2].astype(np.float)\n",
    "total_label=tmp[0:,tmp.shape[1]-1].astype(np.float)\n",
    "\n",
    "import random\n",
    "import math\n",
    "def randomly_pos_points_pick(training_data, training_label, pos_points_ratio_power):\n",
    "    positive_points_index_set = np.where(training_label==1)[0]\n",
    "    num_to_pick = int(math.pow(10, pos_points_ratio_power) * len(training_label))\n",
    "    # Need at least two pos points to apply SMOTE\n",
    "    if num_to_pick < 2:\n",
    "        num_to_pick = 2\n",
    "    random.seed(0)\n",
    "    # Use random.sample to pick up positive points randomly\n",
    "    random_index_set = random.sample(list(positive_points_index_set), num_to_pick)\n",
    "    # Use the index to filter out original training data and training label\n",
    "    print random_index_set\n",
    "    zero_data=training_data[np.where(training_label==0)[0]]\n",
    "    zero_label=training_label[np.where(training_label==0)[0]]\n",
    "    training_data_after_sampling = training_data[random_index_set]\n",
    "    training_label_after_sampling = training_label[random_index_set]\n",
    "    training_data_after_sampling=np.concatenate((zero_data, training_data_after_sampling), axis=0)\n",
    "    training_label_after_sampling = np.concatenate((zero_label, training_label_after_sampling), axis=0)\n",
    "    return training_data_after_sampling, training_label_after_sampling\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "kfold = skf.split(total_data, total_label)\n",
    "K = -1\n",
    "svm_matrix = np.zeros((10, 2, 2))\n",
    "svm_auc = np.zeros((10, 1, 1))\n",
    "svm_recall = np.zeros((10, 1, 1))\n",
    "svm_p = np.zeros((10, 1, 1))\n",
    "svm_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "bn_matrix = np.zeros((10, 2, 2))\n",
    "bn_auc = np.zeros((10, 1, 1))\n",
    "bn_recall = np.zeros((10, 1, 1))\n",
    "bn_p = np.zeros((10, 1, 1))\n",
    "bn_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "\n",
    "randomforest_matrix = np.zeros((10, 2, 2))\n",
    "randomforest_auc = np.zeros((10, 1, 1))\n",
    "randomforest_recall = np.zeros((10, 1, 1))\n",
    "randomforest_p = np.zeros((10, 1, 1))\n",
    "randomforest_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "knn_matrix = np.zeros((10, 2, 2))\n",
    "knn_auc = np.zeros((10, 1, 1))\n",
    "knn_recall = np.zeros((10, 1, 1))\n",
    "knn_p = np.zeros((10, 1, 1))\n",
    "knn_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "lr_matrix = np.zeros((10, 2, 2))\n",
    "lr_auc = np.zeros((10, 1, 1))\n",
    "lr_recall = np.zeros((10, 1, 1))\n",
    "lr_p = np.zeros((10, 1, 1))\n",
    "lr_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "gb_matrix = np.zeros((10, 2, 2))\n",
    "gb_auc = np.zeros((10, 1, 1))\n",
    "gb_recall = np.zeros((10, 1, 1))\n",
    "gb_p = np.zeros((10, 1, 1))\n",
    "gb_F1 = np.zeros((10, 1, 1))\n",
    "c_matrix=np.zeros((2,2))\n",
    "c_matrix[1][1]=0.001\n",
    "c_matrix[0][0]=0.001\n",
    "c_matrix[1][0]=0.001\n",
    "c_matrix[0][1]=0.001\n",
    "for traini, testi in kfold:\n",
    "\tK = K + 1\n",
    "\tdata_train, data_test = total_data[traini], total_data[testi]\n",
    "\tlabel_train, label_test = total_label[traini], total_label[testi]\n",
    "\tline = data_train.size / data_train[0].size\n",
    "\n",
    "    #data_train, label2 = shuffle(data_train, label2, random_state=830)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\tbn = BernoulliNB()\n",
    "\tpredict_label =bn.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=bn.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tbn_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tbn_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tbn_F1[K]=2*(bn_recall[K]*bn_p[K])/(bn_recall[K]+bn_p[K])\n",
    "\tbn_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(bn_F1[K])):\n",
    "\t\tbn_F1[K] = 0\n",
    "\n",
    "\n",
    "\tknn2 = KNeighborsClassifier()\n",
    "\tpredict_label =knn2.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=knn2.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tknn_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tknn_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tknn_F1[K]=2*(knn_recall[K]*knn_p[K])/(knn_recall[K]+knn_p[K])\n",
    "\tknn_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(knn_F1[K])):\n",
    "\t\tknn_F1[K] = 0\n",
    "\n",
    "\n",
    "\tlr2 = LogisticRegression()\n",
    "\tpredict_label =lr2.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=lr2.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tlr_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tlr_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tlr_F1[K]=2*(lr_recall[K]*lr_p[K])/(lr_recall[K]+lr_p[K])\n",
    "\tlr_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(lr_F1[K])):\n",
    "\t\tlr_F1[K] = 0\n",
    "\n",
    "\tgb = GaussianNB()\n",
    "\tpredict_label =gb.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=gb.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tgb_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tgb_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tgb_F1[K]=2*(gb_recall[K]*gb_p[K])/(gb_recall[K]+gb_p[K])\n",
    "\tgb_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(gb_F1[K])):\n",
    "\t\tgb_F1[K] = 0\n",
    "\t\n",
    "\n",
    "\trandomforest = RandomForestClassifier()\n",
    "\tpredict_label = randomforest.fit(data_train, label_train).predict(data_test)\n",
    "\tdf = randomforest.predict_proba(data_test)[:, 1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\trandomforest_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\trandomforest_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\trandomforest_F1[K]=2*(randomforest_recall[K]*randomforest_p[K])/(randomforest_recall[K]+randomforest_p[K])\n",
    "\trandomforest_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(randomforest_F1[K])):\n",
    "\t\trandomforest_F1[K] = 0\n",
    "\n",
    "print \"----------------------Finally-------------------------\"\n",
    "\n",
    "\n",
    "print \"bn\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(bn_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(bn_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(bn_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(bn_F1))\n",
    "\n",
    "print \"knn\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(knn_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(knn_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(knn_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(knn_F1))\n",
    "\n",
    "print \"lr\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(lr_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(lr_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(lr_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(lr_F1))\n",
    "\n",
    "print \"gb\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(gb_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(gb_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(gb_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(gb_F1))\n",
    "\n",
    "print \"randomforest\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(randomforest_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(randomforest_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(randomforest_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(randomforest_F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AID687 Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:119: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:130: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:142: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:165: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:166: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:118: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Finally-------------------------\n",
      "bn\n",
      "The AUC is 0.591 \n",
      "The recall is 0.000 \n",
      "The p is nan \n",
      "The F1 is 0.000 \n",
      "knn\n",
      "The AUC is 0.509 \n",
      "The recall is 0.000 \n",
      "The p is nan \n",
      "The F1 is 0.000 \n",
      "lr\n",
      "The AUC is 0.625 \n",
      "The recall is 0.000 \n",
      "The p is nan \n",
      "The F1 is 0.000 \n",
      "gb\n",
      "The AUC is 0.537 \n",
      "The recall is 0.880 \n",
      "The p is 0.003 \n",
      "The F1 is 0.006 \n",
      "randomforest\n",
      "The AUC is 0.565 \n",
      "The recall is 0.011 \n",
      "The p is nan \n",
      "The F1 is 0.020 \n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import numpy as np  \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.metrics import silhouette_score\n",
    "import sys\n",
    "sys.path.append('/dartfs-hpc/rc/home/t/f00355t/imbalance')\n",
    "from imblearn.over_sampling import SMOTE\n",
    "np.set_printoptions(threshold='nan')\n",
    "tmp = np.loadtxt(\"AID687.csv\", dtype=np.str,skiprows=1, delimiter=\",\")\n",
    "total_data=tmp[0:,0:tmp.shape[1]-2].astype(np.float)\n",
    "total_label=tmp[0:,tmp.shape[1]-1].astype(np.float)\n",
    "\n",
    "import random\n",
    "import math\n",
    "def randomly_pos_points_pick(training_data, training_label, pos_points_ratio_power):\n",
    "    positive_points_index_set = np.where(training_label==1)[0]\n",
    "    num_to_pick = int(math.pow(10, pos_points_ratio_power) * len(training_label))\n",
    "    # Need at least two pos points to apply SMOTE\n",
    "    if num_to_pick < 2:\n",
    "        num_to_pick = 2\n",
    "    random.seed(0)\n",
    "    # Use random.sample to pick up positive points randomly\n",
    "    random_index_set = random.sample(list(positive_points_index_set), num_to_pick)\n",
    "    # Use the index to filter out original training data and training label\n",
    "    print random_index_set\n",
    "    zero_data=training_data[np.where(training_label==0)[0]]\n",
    "    zero_label=training_label[np.where(training_label==0)[0]]\n",
    "    training_data_after_sampling = training_data[random_index_set]\n",
    "    training_label_after_sampling = training_label[random_index_set]\n",
    "    training_data_after_sampling=np.concatenate((zero_data, training_data_after_sampling), axis=0)\n",
    "    training_label_after_sampling = np.concatenate((zero_label, training_label_after_sampling), axis=0)\n",
    "    return training_data_after_sampling, training_label_after_sampling\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "kfold = skf.split(total_data, total_label)\n",
    "K = -1\n",
    "svm_matrix = np.zeros((10, 2, 2))\n",
    "svm_auc = np.zeros((10, 1, 1))\n",
    "svm_recall = np.zeros((10, 1, 1))\n",
    "svm_p = np.zeros((10, 1, 1))\n",
    "svm_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "bn_matrix = np.zeros((10, 2, 2))\n",
    "bn_auc = np.zeros((10, 1, 1))\n",
    "bn_recall = np.zeros((10, 1, 1))\n",
    "bn_p = np.zeros((10, 1, 1))\n",
    "bn_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "\n",
    "randomforest_matrix = np.zeros((10, 2, 2))\n",
    "randomforest_auc = np.zeros((10, 1, 1))\n",
    "randomforest_recall = np.zeros((10, 1, 1))\n",
    "randomforest_p = np.zeros((10, 1, 1))\n",
    "randomforest_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "knn_matrix = np.zeros((10, 2, 2))\n",
    "knn_auc = np.zeros((10, 1, 1))\n",
    "knn_recall = np.zeros((10, 1, 1))\n",
    "knn_p = np.zeros((10, 1, 1))\n",
    "knn_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "lr_matrix = np.zeros((10, 2, 2))\n",
    "lr_auc = np.zeros((10, 1, 1))\n",
    "lr_recall = np.zeros((10, 1, 1))\n",
    "lr_p = np.zeros((10, 1, 1))\n",
    "lr_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "gb_matrix = np.zeros((10, 2, 2))\n",
    "gb_auc = np.zeros((10, 1, 1))\n",
    "gb_recall = np.zeros((10, 1, 1))\n",
    "gb_p = np.zeros((10, 1, 1))\n",
    "gb_F1 = np.zeros((10, 1, 1))\n",
    "c_matrix=np.zeros((2,2))\n",
    "c_matrix[1][1]=0.001\n",
    "c_matrix[0][0]=0.001\n",
    "c_matrix[1][0]=0.001\n",
    "c_matrix[0][1]=0.001\n",
    "for traini, testi in kfold:\n",
    "\tK = K + 1\n",
    "\tdata_train, data_test = total_data[traini], total_data[testi]\n",
    "\tlabel_train, label_test = total_label[traini], total_label[testi]\n",
    "\tline = data_train.size / data_train[0].size\n",
    "\n",
    "    #data_train, label2 = shuffle(data_train, label2, random_state=830)\n",
    "\n",
    "\n",
    "\tbn = BernoulliNB()\n",
    "\tpredict_label =bn.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=bn.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tbn_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tbn_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tbn_F1[K]=2*(bn_recall[K]*bn_p[K])/(bn_recall[K]+bn_p[K])\n",
    "\tbn_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(bn_F1[K])):\n",
    "\t\tbn_F1[K] = 0\n",
    "\n",
    "\n",
    "\tknn2 = KNeighborsClassifier()\n",
    "\tpredict_label =knn2.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=knn2.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tknn_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tknn_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tknn_F1[K]=2*(knn_recall[K]*knn_p[K])/(knn_recall[K]+knn_p[K])\n",
    "\tknn_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(knn_F1[K])):\n",
    "\t\tknn_F1[K] = 0\n",
    "\n",
    "\n",
    "\tlr2 = LogisticRegression()\n",
    "\tpredict_label =lr2.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=lr2.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tlr_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tlr_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tlr_F1[K]=2*(lr_recall[K]*lr_p[K])/(lr_recall[K]+lr_p[K])\n",
    "\tlr_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(lr_F1[K])):\n",
    "\t\tlr_F1[K] = 0\n",
    "\n",
    "\tgb = GaussianNB()\n",
    "\tpredict_label =gb.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=gb.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tgb_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tgb_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tgb_F1[K]=2*(gb_recall[K]*gb_p[K])/(gb_recall[K]+gb_p[K])\n",
    "\tgb_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(gb_F1[K])):\n",
    "\t\tgb_F1[K] = 0\n",
    "\t\n",
    "\n",
    "\trandomforest = RandomForestClassifier()\n",
    "\tpredict_label = randomforest.fit(data_train, label_train).predict(data_test)\n",
    "\tdf = randomforest.predict_proba(data_test)[:, 1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\trandomforest_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\trandomforest_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\trandomforest_F1[K]=2*(randomforest_recall[K]*randomforest_p[K])/(randomforest_recall[K]+randomforest_p[K])\n",
    "\trandomforest_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(randomforest_F1[K])):\n",
    "\t\trandomforest_F1[K] = 0\n",
    "\n",
    "print \"----------------------Finally-------------------------\"\n",
    "\n",
    "\n",
    "print \"bn\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(bn_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(bn_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(bn_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(bn_F1))\n",
    "\n",
    "print \"knn\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(knn_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(knn_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(knn_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(knn_F1))\n",
    "\n",
    "print \"lr\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(lr_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(lr_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(lr_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(lr_F1))\n",
    "\n",
    "print \"gb\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(gb_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(gb_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(gb_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(gb_F1))\n",
    "\n",
    "print \"randomforest\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(randomforest_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(randomforest_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(randomforest_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(randomforest_F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AID688 Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:119: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:130: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:142: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:165: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:131: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:166: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:118: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Finally-------------------------\n",
      "bn\n",
      "The AUC is 0.545 \n",
      "The recall is 0.000 \n",
      "The p is nan \n",
      "The F1 is 0.000 \n",
      "knn\n",
      "The AUC is 0.486 \n",
      "The recall is 0.000 \n",
      "The p is nan \n",
      "The F1 is 0.000 \n",
      "lr\n",
      "The AUC is 0.564 \n",
      "The recall is 0.000 \n",
      "The p is nan \n",
      "The F1 is 0.000 \n",
      "gb\n",
      "The AUC is 0.505 \n",
      "The recall is 0.923 \n",
      "The p is 0.009 \n",
      "The F1 is 0.018 \n",
      "randomforest\n",
      "The AUC is 0.497 \n",
      "The recall is 0.000 \n",
      "The p is nan \n",
      "The F1 is 0.000 \n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import numpy as np  \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.metrics import silhouette_score\n",
    "import sys\n",
    "sys.path.append('/dartfs-hpc/rc/home/t/f00355t/imbalance')\n",
    "from imblearn.over_sampling import SMOTE\n",
    "np.set_printoptions(threshold='nan')\n",
    "tmp = np.loadtxt(\"AID688.csv\", dtype=np.str,skiprows=1, delimiter=\",\")\n",
    "total_data=tmp[0:,0:tmp.shape[1]-2].astype(np.float)\n",
    "total_label=tmp[0:,tmp.shape[1]-1].astype(np.float)\n",
    "\n",
    "import random\n",
    "import math\n",
    "def randomly_pos_points_pick(training_data, training_label, pos_points_ratio_power):\n",
    "    positive_points_index_set = np.where(training_label==1)[0]\n",
    "    num_to_pick = int(math.pow(10, pos_points_ratio_power) * len(training_label))\n",
    "    # Need at least two pos points to apply SMOTE\n",
    "    if num_to_pick < 2:\n",
    "        num_to_pick = 2\n",
    "    random.seed(0)\n",
    "    # Use random.sample to pick up positive points randomly\n",
    "    random_index_set = random.sample(list(positive_points_index_set), num_to_pick)\n",
    "    # Use the index to filter out original training data and training label\n",
    "    print random_index_set\n",
    "    zero_data=training_data[np.where(training_label==0)[0]]\n",
    "    zero_label=training_label[np.where(training_label==0)[0]]\n",
    "    training_data_after_sampling = training_data[random_index_set]\n",
    "    training_label_after_sampling = training_label[random_index_set]\n",
    "    training_data_after_sampling=np.concatenate((zero_data, training_data_after_sampling), axis=0)\n",
    "    training_label_after_sampling = np.concatenate((zero_label, training_label_after_sampling), axis=0)\n",
    "    return training_data_after_sampling, training_label_after_sampling\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "kfold = skf.split(total_data, total_label)\n",
    "K = -1\n",
    "svm_matrix = np.zeros((10, 2, 2))\n",
    "svm_auc = np.zeros((10, 1, 1))\n",
    "svm_recall = np.zeros((10, 1, 1))\n",
    "svm_p = np.zeros((10, 1, 1))\n",
    "svm_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "bn_matrix = np.zeros((10, 2, 2))\n",
    "bn_auc = np.zeros((10, 1, 1))\n",
    "bn_recall = np.zeros((10, 1, 1))\n",
    "bn_p = np.zeros((10, 1, 1))\n",
    "bn_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "\n",
    "randomforest_matrix = np.zeros((10, 2, 2))\n",
    "randomforest_auc = np.zeros((10, 1, 1))\n",
    "randomforest_recall = np.zeros((10, 1, 1))\n",
    "randomforest_p = np.zeros((10, 1, 1))\n",
    "randomforest_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "knn_matrix = np.zeros((10, 2, 2))\n",
    "knn_auc = np.zeros((10, 1, 1))\n",
    "knn_recall = np.zeros((10, 1, 1))\n",
    "knn_p = np.zeros((10, 1, 1))\n",
    "knn_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "lr_matrix = np.zeros((10, 2, 2))\n",
    "lr_auc = np.zeros((10, 1, 1))\n",
    "lr_recall = np.zeros((10, 1, 1))\n",
    "lr_p = np.zeros((10, 1, 1))\n",
    "lr_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "gb_matrix = np.zeros((10, 2, 2))\n",
    "gb_auc = np.zeros((10, 1, 1))\n",
    "gb_recall = np.zeros((10, 1, 1))\n",
    "gb_p = np.zeros((10, 1, 1))\n",
    "gb_F1 = np.zeros((10, 1, 1))\n",
    "c_matrix=np.zeros((2,2))\n",
    "c_matrix[1][1]=0.001\n",
    "c_matrix[0][0]=0.001\n",
    "c_matrix[1][0]=0.001\n",
    "c_matrix[0][1]=0.001\n",
    "for traini, testi in kfold:\n",
    "\tK = K + 1\n",
    "\tdata_train, data_test = total_data[traini], total_data[testi]\n",
    "\tlabel_train, label_test = total_label[traini], total_label[testi]\n",
    "\tline = data_train.size / data_train[0].size\n",
    "\n",
    "    #data_train, label2 = shuffle(data_train, label2, random_state=830)\n",
    "\n",
    "\n",
    "\tbn = BernoulliNB()\n",
    "\tpredict_label =bn.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=bn.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tbn_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tbn_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tbn_F1[K]=2*(bn_recall[K]*bn_p[K])/(bn_recall[K]+bn_p[K])\n",
    "\tbn_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(bn_F1[K])):\n",
    "\t\tbn_F1[K] = 0\n",
    "\n",
    "\n",
    "\tknn2 = KNeighborsClassifier()\n",
    "\tpredict_label =knn2.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=knn2.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tknn_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tknn_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tknn_F1[K]=2*(knn_recall[K]*knn_p[K])/(knn_recall[K]+knn_p[K])\n",
    "\tknn_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(knn_F1[K])):\n",
    "\t\tknn_F1[K] = 0\n",
    "\n",
    "\n",
    "\tlr2 = LogisticRegression()\n",
    "\tpredict_label =lr2.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=lr2.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tlr_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tlr_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tlr_F1[K]=2*(lr_recall[K]*lr_p[K])/(lr_recall[K]+lr_p[K])\n",
    "\tlr_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(lr_F1[K])):\n",
    "\t\tlr_F1[K] = 0\n",
    "\n",
    "\tgb = GaussianNB()\n",
    "\tpredict_label =gb.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=gb.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tgb_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tgb_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tgb_F1[K]=2*(gb_recall[K]*gb_p[K])/(gb_recall[K]+gb_p[K])\n",
    "\tgb_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(gb_F1[K])):\n",
    "\t\tgb_F1[K] = 0\n",
    "\t\n",
    "\n",
    "\trandomforest = RandomForestClassifier()\n",
    "\tpredict_label = randomforest.fit(data_train, label_train).predict(data_test)\n",
    "\tdf = randomforest.predict_proba(data_test)[:, 1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\trandomforest_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\trandomforest_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\trandomforest_F1[K]=2*(randomforest_recall[K]*randomforest_p[K])/(randomforest_recall[K]+randomforest_p[K])\n",
    "\trandomforest_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(randomforest_F1[K])):\n",
    "\t\trandomforest_F1[K] = 0\n",
    "\n",
    "print \"----------------------Finally-------------------------\"\n",
    "\n",
    "\n",
    "print \"bn\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(bn_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(bn_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(bn_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(bn_F1))\n",
    "\n",
    "print \"knn\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(knn_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(knn_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(knn_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(knn_F1))\n",
    "\n",
    "print \"lr\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(lr_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(lr_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(lr_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(lr_F1))\n",
    "\n",
    "print \"gb\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(gb_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(gb_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(gb_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(gb_F1))\n",
    "\n",
    "print \"randomforest\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(randomforest_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(randomforest_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(randomforest_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(randomforest_F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AID373 dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:119: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:130: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:142: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:154: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:165: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:166: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Finally-------------------------\n",
      "bn\n",
      "The AUC is 0.764 \n",
      "The recall is 0.000 \n",
      "The p is 0.000 \n",
      "The F1 is 0.000 \n",
      "knn\n",
      "The AUC is 0.600 \n",
      "The recall is 0.000 \n",
      "The p is nan \n",
      "The F1 is 0.000 \n",
      "lr\n",
      "The AUC is 0.736 \n",
      "The recall is 0.000 \n",
      "The p is nan \n",
      "The F1 is 0.000 \n",
      "gb\n",
      "The AUC is 0.459 \n",
      "The recall is 0.400 \n",
      "The p is 0.000 \n",
      "The F1 is 0.000 \n",
      "randomforest\n",
      "The AUC is 0.649 \n",
      "The recall is 0.000 \n",
      "The p is nan \n",
      "The F1 is 0.000 \n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import numpy as np  \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.metrics import silhouette_score\n",
    "import sys\n",
    "sys.path.append('/dartfs-hpc/rc/home/t/f00355t/imbalance')\n",
    "from imblearn.over_sampling import SMOTE\n",
    "np.set_printoptions(threshold='nan')\n",
    "tmp = np.loadtxt(\"AID373.csv\", dtype=np.str,skiprows=1, delimiter=\",\")\n",
    "total_data=tmp[0:,0:tmp.shape[1]-2].astype(np.float)\n",
    "total_label=tmp[0:,tmp.shape[1]-1].astype(np.float)\n",
    "\n",
    "import random\n",
    "import math\n",
    "def randomly_pos_points_pick(training_data, training_label, pos_points_ratio_power):\n",
    "    positive_points_index_set = np.where(training_label==1)[0]\n",
    "    num_to_pick = int(math.pow(10, pos_points_ratio_power) * len(training_label))\n",
    "    # Need at least two pos points to apply SMOTE\n",
    "    if num_to_pick < 2:\n",
    "        num_to_pick = 2\n",
    "    random.seed(0)\n",
    "    # Use random.sample to pick up positive points randomly\n",
    "    random_index_set = random.sample(list(positive_points_index_set), num_to_pick)\n",
    "    # Use the index to filter out original training data and training label\n",
    "    print random_index_set\n",
    "    zero_data=training_data[np.where(training_label==0)[0]]\n",
    "    zero_label=training_label[np.where(training_label==0)[0]]\n",
    "    training_data_after_sampling = training_data[random_index_set]\n",
    "    training_label_after_sampling = training_label[random_index_set]\n",
    "    training_data_after_sampling=np.concatenate((zero_data, training_data_after_sampling), axis=0)\n",
    "    training_label_after_sampling = np.concatenate((zero_label, training_label_after_sampling), axis=0)\n",
    "    return training_data_after_sampling, training_label_after_sampling\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "kfold = skf.split(total_data, total_label)\n",
    "K = -1\n",
    "svm_matrix = np.zeros((10, 2, 2))\n",
    "svm_auc = np.zeros((10, 1, 1))\n",
    "svm_recall = np.zeros((10, 1, 1))\n",
    "svm_p = np.zeros((10, 1, 1))\n",
    "svm_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "bn_matrix = np.zeros((10, 2, 2))\n",
    "bn_auc = np.zeros((10, 1, 1))\n",
    "bn_recall = np.zeros((10, 1, 1))\n",
    "bn_p = np.zeros((10, 1, 1))\n",
    "bn_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "\n",
    "randomforest_matrix = np.zeros((10, 2, 2))\n",
    "randomforest_auc = np.zeros((10, 1, 1))\n",
    "randomforest_recall = np.zeros((10, 1, 1))\n",
    "randomforest_p = np.zeros((10, 1, 1))\n",
    "randomforest_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "knn_matrix = np.zeros((10, 2, 2))\n",
    "knn_auc = np.zeros((10, 1, 1))\n",
    "knn_recall = np.zeros((10, 1, 1))\n",
    "knn_p = np.zeros((10, 1, 1))\n",
    "knn_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "lr_matrix = np.zeros((10, 2, 2))\n",
    "lr_auc = np.zeros((10, 1, 1))\n",
    "lr_recall = np.zeros((10, 1, 1))\n",
    "lr_p = np.zeros((10, 1, 1))\n",
    "lr_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "gb_matrix = np.zeros((10, 2, 2))\n",
    "gb_auc = np.zeros((10, 1, 1))\n",
    "gb_recall = np.zeros((10, 1, 1))\n",
    "gb_p = np.zeros((10, 1, 1))\n",
    "gb_F1 = np.zeros((10, 1, 1))\n",
    "c_matrix=np.zeros((2,2))\n",
    "c_matrix[1][1]=0.001\n",
    "c_matrix[0][0]=0.001\n",
    "c_matrix[1][0]=0.001\n",
    "c_matrix[0][1]=0.001\n",
    "for traini, testi in kfold:\n",
    "\tK = K + 1\n",
    "\tdata_train, data_test = total_data[traini], total_data[testi]\n",
    "\tlabel_train, label_test = total_label[traini], total_label[testi]\n",
    "\tline = data_train.size / data_train[0].size\n",
    "\n",
    "    #data_train, label2 = shuffle(data_train, label2, random_state=830)\n",
    "\n",
    "\n",
    "\tbn = BernoulliNB()\n",
    "\tpredict_label =bn.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=bn.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tbn_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tbn_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tbn_F1[K]=2*(bn_recall[K]*bn_p[K])/(bn_recall[K]+bn_p[K])\n",
    "\tbn_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(bn_F1[K])):\n",
    "\t\tbn_F1[K] = 0\n",
    "\n",
    "\n",
    "\tknn2 = KNeighborsClassifier()\n",
    "\tpredict_label =knn2.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=knn2.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tknn_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tknn_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tknn_F1[K]=2*(knn_recall[K]*knn_p[K])/(knn_recall[K]+knn_p[K])\n",
    "\tknn_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(knn_F1[K])):\n",
    "\t\tknn_F1[K] = 0\n",
    "\n",
    "\n",
    "\tlr2 = LogisticRegression()\n",
    "\tpredict_label =lr2.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=lr2.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tlr_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tlr_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tlr_F1[K]=2*(lr_recall[K]*lr_p[K])/(lr_recall[K]+lr_p[K])\n",
    "\tlr_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(lr_F1[K])):\n",
    "\t\tlr_F1[K] = 0\n",
    "\n",
    "\tgb = GaussianNB()\n",
    "\tpredict_label =gb.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=gb.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tgb_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tgb_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tgb_F1[K]=2*(gb_recall[K]*gb_p[K])/(gb_recall[K]+gb_p[K])\n",
    "\tgb_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(gb_F1[K])):\n",
    "\t\tgb_F1[K] = 0\n",
    "\t\n",
    "\n",
    "\trandomforest = RandomForestClassifier()\n",
    "\tpredict_label = randomforest.fit(data_train, label_train).predict(data_test)\n",
    "\tdf = randomforest.predict_proba(data_test)[:, 1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\trandomforest_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\trandomforest_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\trandomforest_F1[K]=2*(randomforest_recall[K]*randomforest_p[K])/(randomforest_recall[K]+randomforest_p[K])\n",
    "\trandomforest_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(randomforest_F1[K])):\n",
    "\t\trandomforest_F1[K] = 0\n",
    "\n",
    "print \"----------------------Finally-------------------------\"\n",
    "\n",
    "\n",
    "print \"bn\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(bn_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(bn_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(bn_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(bn_F1))\n",
    "\n",
    "print \"knn\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(knn_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(knn_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(knn_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(knn_F1))\n",
    "\n",
    "print \"lr\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(lr_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(lr_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(lr_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(lr_F1))\n",
    "\n",
    "print \"gb\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(gb_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(gb_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(gb_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(gb_F1))\n",
    "\n",
    "print \"randomforest\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(randomforest_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(randomforest_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(randomforest_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(randomforest_F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AID604 daset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:119: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:130: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:142: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:166: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:165: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:118: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:131: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Finally-------------------------\n",
      "bn\n",
      "The AUC is 0.688 \n",
      "The recall is 0.000 \n",
      "The p is nan \n",
      "The F1 is 0.000 \n",
      "knn\n",
      "The AUC is 0.566 \n",
      "The recall is 0.000 \n",
      "The p is nan \n",
      "The F1 is 0.000 \n",
      "lr\n",
      "The AUC is 0.804 \n",
      "The recall is 0.000 \n",
      "The p is nan \n",
      "The F1 is 0.000 \n",
      "gb\n",
      "The AUC is 0.547 \n",
      "The recall is 0.948 \n",
      "The p is 0.004 \n",
      "The F1 is 0.008 \n",
      "randomforest\n",
      "The AUC is 0.628 \n",
      "The recall is 0.043 \n",
      "The p is nan \n",
      "The F1 is 0.077 \n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import numpy as np  \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.metrics import silhouette_score\n",
    "import sys\n",
    "sys.path.append('/dartfs-hpc/rc/home/t/f00355t/imbalance')\n",
    "from imblearn.over_sampling import SMOTE\n",
    "np.set_printoptions(threshold='nan')\n",
    "tmp = np.loadtxt(\"AID604.csv\", dtype=np.str,skiprows=1, delimiter=\",\")\n",
    "total_data=tmp[0:,0:tmp.shape[1]-2].astype(np.float)\n",
    "total_label=tmp[0:,tmp.shape[1]-1].astype(np.float)\n",
    "\n",
    "import random\n",
    "import math\n",
    "def randomly_pos_points_pick(training_data, training_label, pos_points_ratio_power):\n",
    "    positive_points_index_set = np.where(training_label==1)[0]\n",
    "    num_to_pick = int(math.pow(10, pos_points_ratio_power) * len(training_label))\n",
    "    # Need at least two pos points to apply SMOTE\n",
    "    if num_to_pick < 2:\n",
    "        num_to_pick = 2\n",
    "    random.seed(0)\n",
    "    # Use random.sample to pick up positive points randomly\n",
    "    random_index_set = random.sample(list(positive_points_index_set), num_to_pick)\n",
    "    # Use the index to filter out original training data and training label\n",
    "    print random_index_set\n",
    "    zero_data=training_data[np.where(training_label==0)[0]]\n",
    "    zero_label=training_label[np.where(training_label==0)[0]]\n",
    "    training_data_after_sampling = training_data[random_index_set]\n",
    "    training_label_after_sampling = training_label[random_index_set]\n",
    "    training_data_after_sampling=np.concatenate((zero_data, training_data_after_sampling), axis=0)\n",
    "    training_label_after_sampling = np.concatenate((zero_label, training_label_after_sampling), axis=0)\n",
    "    return training_data_after_sampling, training_label_after_sampling\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "kfold = skf.split(total_data, total_label)\n",
    "K = -1\n",
    "svm_matrix = np.zeros((10, 2, 2))\n",
    "svm_auc = np.zeros((10, 1, 1))\n",
    "svm_recall = np.zeros((10, 1, 1))\n",
    "svm_p = np.zeros((10, 1, 1))\n",
    "svm_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "bn_matrix = np.zeros((10, 2, 2))\n",
    "bn_auc = np.zeros((10, 1, 1))\n",
    "bn_recall = np.zeros((10, 1, 1))\n",
    "bn_p = np.zeros((10, 1, 1))\n",
    "bn_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "\n",
    "randomforest_matrix = np.zeros((10, 2, 2))\n",
    "randomforest_auc = np.zeros((10, 1, 1))\n",
    "randomforest_recall = np.zeros((10, 1, 1))\n",
    "randomforest_p = np.zeros((10, 1, 1))\n",
    "randomforest_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "knn_matrix = np.zeros((10, 2, 2))\n",
    "knn_auc = np.zeros((10, 1, 1))\n",
    "knn_recall = np.zeros((10, 1, 1))\n",
    "knn_p = np.zeros((10, 1, 1))\n",
    "knn_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "lr_matrix = np.zeros((10, 2, 2))\n",
    "lr_auc = np.zeros((10, 1, 1))\n",
    "lr_recall = np.zeros((10, 1, 1))\n",
    "lr_p = np.zeros((10, 1, 1))\n",
    "lr_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "gb_matrix = np.zeros((10, 2, 2))\n",
    "gb_auc = np.zeros((10, 1, 1))\n",
    "gb_recall = np.zeros((10, 1, 1))\n",
    "gb_p = np.zeros((10, 1, 1))\n",
    "gb_F1 = np.zeros((10, 1, 1))\n",
    "c_matrix=np.zeros((2,2))\n",
    "c_matrix[1][1]=0.001\n",
    "c_matrix[0][0]=0.001\n",
    "c_matrix[1][0]=0.001\n",
    "c_matrix[0][1]=0.001\n",
    "for traini, testi in kfold:\n",
    "\tK = K + 1\n",
    "\tdata_train, data_test = total_data[traini], total_data[testi]\n",
    "\tlabel_train, label_test = total_label[traini], total_label[testi]\n",
    "\tline = data_train.size / data_train[0].size\n",
    "\n",
    "    #data_train, label2 = shuffle(data_train, label2, random_state=830)\n",
    "\n",
    "\n",
    "\tbn = BernoulliNB()\n",
    "\tpredict_label =bn.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=bn.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tbn_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tbn_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tbn_F1[K]=2*(bn_recall[K]*bn_p[K])/(bn_recall[K]+bn_p[K])\n",
    "\tbn_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(bn_F1[K])):\n",
    "\t\tbn_F1[K] = 0\n",
    "\n",
    "\n",
    "\tknn2 = KNeighborsClassifier()\n",
    "\tpredict_label =knn2.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=knn2.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tknn_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tknn_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tknn_F1[K]=2*(knn_recall[K]*knn_p[K])/(knn_recall[K]+knn_p[K])\n",
    "\tknn_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(knn_F1[K])):\n",
    "\t\tknn_F1[K] = 0\n",
    "\n",
    "\n",
    "\tlr2 = LogisticRegression()\n",
    "\tpredict_label =lr2.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=lr2.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tlr_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tlr_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tlr_F1[K]=2*(lr_recall[K]*lr_p[K])/(lr_recall[K]+lr_p[K])\n",
    "\tlr_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(lr_F1[K])):\n",
    "\t\tlr_F1[K] = 0\n",
    "\n",
    "\tgb = GaussianNB()\n",
    "\tpredict_label =gb.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=gb.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tgb_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tgb_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tgb_F1[K]=2*(gb_recall[K]*gb_p[K])/(gb_recall[K]+gb_p[K])\n",
    "\tgb_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(gb_F1[K])):\n",
    "\t\tgb_F1[K] = 0\n",
    "\t\n",
    "\n",
    "\trandomforest = RandomForestClassifier()\n",
    "\tpredict_label = randomforest.fit(data_train, label_train).predict(data_test)\n",
    "\tdf = randomforest.predict_proba(data_test)[:, 1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\trandomforest_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\trandomforest_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\trandomforest_F1[K]=2*(randomforest_recall[K]*randomforest_p[K])/(randomforest_recall[K]+randomforest_p[K])\n",
    "\trandomforest_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(randomforest_F1[K])):\n",
    "\t\trandomforest_F1[K] = 0\n",
    "\n",
    "print \"----------------------Finally-------------------------\"\n",
    "\n",
    "\n",
    "print \"bn\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(bn_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(bn_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(bn_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(bn_F1))\n",
    "\n",
    "print \"knn\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(knn_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(knn_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(knn_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(knn_F1))\n",
    "\n",
    "print \"lr\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(lr_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(lr_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(lr_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(lr_F1))\n",
    "\n",
    "print \"gb\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(gb_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(gb_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(gb_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(gb_F1))\n",
    "\n",
    "print \"randomforest\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(randomforest_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(randomforest_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(randomforest_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(randomforest_F1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
