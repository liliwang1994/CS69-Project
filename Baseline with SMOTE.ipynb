{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTRU2 Dataset \n",
    "## with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Finally-------------------------\n",
      "bn\n",
      "The AUC is 0.764 \n",
      "The recall is 0.973 \n",
      "The p is 0.166 \n",
      "The F1 is 0.284 \n",
      "knn\n",
      "The AUC is 0.937 \n",
      "The recall is 0.876 \n",
      "The p is 0.589 \n",
      "The F1 is 0.703 \n",
      "lr\n",
      "The AUC is 0.976 \n",
      "The recall is 0.908 \n",
      "The p is 0.785 \n",
      "The F1 is 0.840 \n",
      "gb\n",
      "The AUC is 0.958 \n",
      "The recall is 0.855 \n",
      "The p is 0.646 \n",
      "The F1 is 0.730 \n",
      "randomforest\n",
      "The AUC is 0.964 \n",
      "The recall is 0.882 \n",
      "The p is 0.835 \n",
      "The F1 is 0.856 \n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.metrics import silhouette_score\n",
    "import sys\n",
    "sys.path.append('/dartfs-hpc/rc/home/t/f00355t/imbalance')\n",
    "from imblearn.over_sampling import SMOTE\n",
    "np.set_printoptions(threshold='nan')\n",
    "tmp = np.loadtxt(\"HTRU_2.csv\", dtype=np.str,skiprows=1, delimiter=\",\")\n",
    "total_data=tmp[0:,0:tmp.shape[1]-2].astype(np.float)\n",
    "total_label=tmp[0:,tmp.shape[1]-1].astype(np.float)\n",
    "\n",
    "import random\n",
    "import math\n",
    "def randomly_pos_points_pick(training_data, training_label, pos_points_ratio_power):\n",
    "    positive_points_index_set = np.where(training_label==1)[0]\n",
    "    num_to_pick = int(math.pow(10, pos_points_ratio_power) * len(training_label))\n",
    "    # Need at least two pos points to apply SMOTE\n",
    "    if num_to_pick < 2:\n",
    "        num_to_pick = 2\n",
    "    random.seed(0)\n",
    "    # Use random.sample to pick up positive points randomly\n",
    "    random_index_set = random.sample(list(positive_points_index_set), num_to_pick)\n",
    "    # Use the index to filter out original training data and training label\n",
    "    print random_index_set\n",
    "    zero_data=training_data[np.where(training_label==0)[0]]\n",
    "    zero_label=training_label[np.where(training_label==0)[0]]\n",
    "    training_data_after_sampling = training_data[random_index_set]\n",
    "    training_label_after_sampling = training_label[random_index_set]\n",
    "    training_data_after_sampling=np.concatenate((zero_data, training_data_after_sampling), axis=0)\n",
    "    training_label_after_sampling = np.concatenate((zero_label, training_label_after_sampling), axis=0)\n",
    "    return training_data_after_sampling, training_label_after_sampling\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "kfold = skf.split(total_data, total_label)\n",
    "K = -1\n",
    "svm_matrix = np.zeros((10, 2, 2))\n",
    "svm_auc = np.zeros((10, 1, 1))\n",
    "svm_recall = np.zeros((10, 1, 1))\n",
    "svm_p = np.zeros((10, 1, 1))\n",
    "svm_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "bn_matrix = np.zeros((10, 2, 2))\n",
    "bn_auc = np.zeros((10, 1, 1))\n",
    "bn_recall = np.zeros((10, 1, 1))\n",
    "bn_p = np.zeros((10, 1, 1))\n",
    "bn_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "\n",
    "randomforest_matrix = np.zeros((10, 2, 2))\n",
    "randomforest_auc = np.zeros((10, 1, 1))\n",
    "randomforest_recall = np.zeros((10, 1, 1))\n",
    "randomforest_p = np.zeros((10, 1, 1))\n",
    "randomforest_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "knn_matrix = np.zeros((10, 2, 2))\n",
    "knn_auc = np.zeros((10, 1, 1))\n",
    "knn_recall = np.zeros((10, 1, 1))\n",
    "knn_p = np.zeros((10, 1, 1))\n",
    "knn_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "lr_matrix = np.zeros((10, 2, 2))\n",
    "lr_auc = np.zeros((10, 1, 1))\n",
    "lr_recall = np.zeros((10, 1, 1))\n",
    "lr_p = np.zeros((10, 1, 1))\n",
    "lr_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "gb_matrix = np.zeros((10, 2, 2))\n",
    "gb_auc = np.zeros((10, 1, 1))\n",
    "gb_recall = np.zeros((10, 1, 1))\n",
    "gb_p = np.zeros((10, 1, 1))\n",
    "gb_F1 = np.zeros((10, 1, 1))\n",
    "c_matrix=np.zeros((2,2))\n",
    "c_matrix[1][1]=0.001\n",
    "c_matrix[0][0]=0.001\n",
    "c_matrix[1][0]=0.001\n",
    "c_matrix[0][1]=0.001\n",
    "for traini, testi in kfold:\n",
    "\tK = K + 1\n",
    "\tdata_train, data_test = total_data[traini], total_data[testi]\n",
    "\tlabel_train, label_test = total_label[traini], total_label[testi]\n",
    "\tsm = SMOTE(random_state=1)\n",
    "\tdata_train, label_train = sm.fit_sample(data_train, label_train)\n",
    "\tline = data_train.size / data_train[0].size\n",
    "\n",
    "    #data_train, label2 = shuffle(data_train, label2, random_state=830)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\tbn = BernoulliNB()\n",
    "\tpredict_label =bn.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=bn.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tbn_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tbn_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tbn_F1[K]=2*(bn_recall[K]*bn_p[K])/(bn_recall[K]+bn_p[K])\n",
    "\tbn_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(bn_F1[K])):\n",
    "\t\tbn_F1[K] = 0\n",
    "\n",
    "\n",
    "\tknn2 = KNeighborsClassifier()\n",
    "\tpredict_label =knn2.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=knn2.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tknn_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tknn_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tknn_F1[K]=2*(knn_recall[K]*knn_p[K])/(knn_recall[K]+knn_p[K])\n",
    "\tknn_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(knn_F1[K])):\n",
    "\t\tknn_F1[K] = 0\n",
    "\n",
    "\n",
    "\tlr2 = LogisticRegression()\n",
    "\tpredict_label =lr2.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=lr2.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tlr_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tlr_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tlr_F1[K]=2*(lr_recall[K]*lr_p[K])/(lr_recall[K]+lr_p[K])\n",
    "\tlr_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(lr_F1[K])):\n",
    "\t\tlr_F1[K] = 0\n",
    "\n",
    "\tgb = GaussianNB()\n",
    "\tpredict_label =gb.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=gb.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tgb_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tgb_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tgb_F1[K]=2*(gb_recall[K]*gb_p[K])/(gb_recall[K]+gb_p[K])\n",
    "\tgb_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(gb_F1[K])):\n",
    "\t\tgb_F1[K] = 0\n",
    "\t\n",
    "\n",
    "\trandomforest = RandomForestClassifier()\n",
    "\tpredict_label = randomforest.fit(data_train, label_train).predict(data_test)\n",
    "\tdf = randomforest.predict_proba(data_test)[:, 1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\trandomforest_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\trandomforest_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\trandomforest_F1[K]=2*(randomforest_recall[K]*randomforest_p[K])/(randomforest_recall[K]+randomforest_p[K])\n",
    "\trandomforest_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(randomforest_F1[K])):\n",
    "\t\trandomforest_F1[K] = 0\n",
    "\n",
    "print \"----------------------Finally-------------------------\"\n",
    "\n",
    "\n",
    "print \"bn\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(bn_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(bn_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(bn_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(bn_F1))\n",
    "\n",
    "print \"knn\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(knn_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(knn_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(knn_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(knn_F1))\n",
    "\n",
    "print \"lr\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(lr_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(lr_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(lr_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(lr_F1))\n",
    "\n",
    "print \"gb\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(gb_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(gb_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(gb_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(gb_F1))\n",
    "\n",
    "print \"randomforest\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(randomforest_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(randomforest_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(randomforest_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(randomforest_F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AID687 Dataset with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:133: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Finally-------------------------\n",
      "bn\n",
      "The AUC is 0.612 \n",
      "The recall is 0.204 \n",
      "The p is 0.004 \n",
      "The F1 is 0.008 \n",
      "knn\n",
      "The AUC is 0.568 \n",
      "The recall is 0.261 \n",
      "The p is 0.005 \n",
      "The F1 is 0.010 \n",
      "lr\n",
      "The AUC is 0.630 \n",
      "The recall is 0.449 \n",
      "The p is 0.005 \n",
      "The F1 is 0.011 \n",
      "gb\n",
      "The AUC is 0.537 \n",
      "The recall is 0.880 \n",
      "The p is 0.003 \n",
      "The F1 is 0.006 \n",
      "randomforest\n",
      "The AUC is 0.536 \n",
      "The recall is 0.081 \n",
      "The p is 0.027 \n",
      "The F1 is 0.041 \n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import numpy as np  \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.metrics import silhouette_score\n",
    "import sys\n",
    "sys.path.append('/dartfs-hpc/rc/home/t/f00355t/imbalance')\n",
    "from imblearn.over_sampling import SMOTE\n",
    "np.set_printoptions(threshold='nan')\n",
    "tmp = np.loadtxt(\"AID687.csv\", dtype=np.str,skiprows=1, delimiter=\",\")\n",
    "total_data=tmp[0:,0:tmp.shape[1]-2].astype(np.float)\n",
    "total_label=tmp[0:,tmp.shape[1]-1].astype(np.float)\n",
    "\n",
    "import random\n",
    "import math\n",
    "def randomly_pos_points_pick(training_data, training_label, pos_points_ratio_power):\n",
    "    positive_points_index_set = np.where(training_label==1)[0]\n",
    "    num_to_pick = int(math.pow(10, pos_points_ratio_power) * len(training_label))\n",
    "    # Need at least two pos points to apply SMOTE\n",
    "    if num_to_pick < 2:\n",
    "        num_to_pick = 2\n",
    "    random.seed(0)\n",
    "    # Use random.sample to pick up positive points randomly\n",
    "    random_index_set = random.sample(list(positive_points_index_set), num_to_pick)\n",
    "    # Use the index to filter out original training data and training label\n",
    "    print random_index_set\n",
    "    zero_data=training_data[np.where(training_label==0)[0]]\n",
    "    zero_label=training_label[np.where(training_label==0)[0]]\n",
    "    training_data_after_sampling = training_data[random_index_set]\n",
    "    training_label_after_sampling = training_label[random_index_set]\n",
    "    training_data_after_sampling=np.concatenate((zero_data, training_data_after_sampling), axis=0)\n",
    "    training_label_after_sampling = np.concatenate((zero_label, training_label_after_sampling), axis=0)\n",
    "    return training_data_after_sampling, training_label_after_sampling\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "kfold = skf.split(total_data, total_label)\n",
    "K = -1\n",
    "svm_matrix = np.zeros((10, 2, 2))\n",
    "svm_auc = np.zeros((10, 1, 1))\n",
    "svm_recall = np.zeros((10, 1, 1))\n",
    "svm_p = np.zeros((10, 1, 1))\n",
    "svm_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "bn_matrix = np.zeros((10, 2, 2))\n",
    "bn_auc = np.zeros((10, 1, 1))\n",
    "bn_recall = np.zeros((10, 1, 1))\n",
    "bn_p = np.zeros((10, 1, 1))\n",
    "bn_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "\n",
    "randomforest_matrix = np.zeros((10, 2, 2))\n",
    "randomforest_auc = np.zeros((10, 1, 1))\n",
    "randomforest_recall = np.zeros((10, 1, 1))\n",
    "randomforest_p = np.zeros((10, 1, 1))\n",
    "randomforest_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "knn_matrix = np.zeros((10, 2, 2))\n",
    "knn_auc = np.zeros((10, 1, 1))\n",
    "knn_recall = np.zeros((10, 1, 1))\n",
    "knn_p = np.zeros((10, 1, 1))\n",
    "knn_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "lr_matrix = np.zeros((10, 2, 2))\n",
    "lr_auc = np.zeros((10, 1, 1))\n",
    "lr_recall = np.zeros((10, 1, 1))\n",
    "lr_p = np.zeros((10, 1, 1))\n",
    "lr_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "gb_matrix = np.zeros((10, 2, 2))\n",
    "gb_auc = np.zeros((10, 1, 1))\n",
    "gb_recall = np.zeros((10, 1, 1))\n",
    "gb_p = np.zeros((10, 1, 1))\n",
    "gb_F1 = np.zeros((10, 1, 1))\n",
    "c_matrix=np.zeros((2,2))\n",
    "c_matrix[1][1]=0.001\n",
    "c_matrix[0][0]=0.001\n",
    "c_matrix[1][0]=0.001\n",
    "c_matrix[0][1]=0.001\n",
    "for traini, testi in kfold:\n",
    "\tK = K + 1\n",
    "\tdata_train, data_test = total_data[traini], total_data[testi]\n",
    "\tlabel_train, label_test = total_label[traini], total_label[testi]\n",
    "\tsm = SMOTE(random_state=1)\n",
    "\tdata_train, label_train = sm.fit_sample(data_train, label_train)\n",
    "\tline = data_train.size / data_train[0].size\n",
    "\n",
    "    #data_train, label2 = shuffle(data_train, label2, random_state=830)\n",
    "\n",
    "\n",
    "\tbn = BernoulliNB()\n",
    "\tpredict_label =bn.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=bn.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tbn_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tbn_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tbn_F1[K]=2*(bn_recall[K]*bn_p[K])/(bn_recall[K]+bn_p[K])\n",
    "\tbn_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(bn_F1[K])):\n",
    "\t\tbn_F1[K] = 0\n",
    "\n",
    "\n",
    "\tknn2 = KNeighborsClassifier()\n",
    "\tpredict_label =knn2.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=knn2.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tknn_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tknn_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tknn_F1[K]=2*(knn_recall[K]*knn_p[K])/(knn_recall[K]+knn_p[K])\n",
    "\tknn_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(knn_F1[K])):\n",
    "\t\tknn_F1[K] = 0\n",
    "\n",
    "\n",
    "\tlr2 = LogisticRegression()\n",
    "\tpredict_label =lr2.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=lr2.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tlr_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tlr_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tlr_F1[K]=2*(lr_recall[K]*lr_p[K])/(lr_recall[K]+lr_p[K])\n",
    "\tlr_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(lr_F1[K])):\n",
    "\t\tlr_F1[K] = 0\n",
    "\n",
    "\tgb = GaussianNB()\n",
    "\tpredict_label =gb.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=gb.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tgb_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tgb_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tgb_F1[K]=2*(gb_recall[K]*gb_p[K])/(gb_recall[K]+gb_p[K])\n",
    "\tgb_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(gb_F1[K])):\n",
    "\t\tgb_F1[K] = 0\n",
    "\t\n",
    "\n",
    "\trandomforest = RandomForestClassifier(n_estimators=1)\n",
    "\tpredict_label = randomforest.fit(data_train, label_train).predict(data_test)\n",
    "\tdf = randomforest.predict_proba(data_test)[:, 1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\trandomforest_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\trandomforest_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\trandomforest_F1[K]=2*(randomforest_recall[K]*randomforest_p[K])/(randomforest_recall[K]+randomforest_p[K])\n",
    "\trandomforest_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(randomforest_F1[K])):\n",
    "\t\trandomforest_F1[K] = 0\n",
    "\n",
    "print \"----------------------Finally-------------------------\"\n",
    "\n",
    "\n",
    "print \"bn\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(bn_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(bn_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(bn_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(bn_F1))\n",
    "\n",
    "print \"knn\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(knn_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(knn_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(knn_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(knn_F1))\n",
    "\n",
    "print \"lr\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(lr_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(lr_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(lr_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(lr_F1))\n",
    "\n",
    "print \"gb\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(gb_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(gb_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(gb_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(gb_F1))\n",
    "\n",
    "print \"randomforest\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(randomforest_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(randomforest_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(randomforest_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(randomforest_F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AID688 Dataset with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:167: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Finally-------------------------\n",
      "bn\n",
      "The AUC is 0.540 \n",
      "The recall is 0.209 \n",
      "The p is 0.010 \n",
      "The F1 is 0.019 \n",
      "knn\n",
      "The AUC is 0.506 \n",
      "The recall is 0.221 \n",
      "The p is 0.010 \n",
      "The F1 is 0.019 \n",
      "lr\n",
      "The AUC is 0.559 \n",
      "The recall is 0.435 \n",
      "The p is 0.011 \n",
      "The F1 is 0.022 \n",
      "gb\n",
      "The AUC is 0.516 \n",
      "The recall is 0.887 \n",
      "The p is 0.009 \n",
      "The F1 is 0.018 \n",
      "randomforest\n",
      "The AUC is 0.493 \n",
      "The recall is 0.000 \n",
      "The p is nan \n",
      "The F1 is 0.000 \n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import numpy as np  \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.metrics import silhouette_score\n",
    "import sys\n",
    "sys.path.append('/dartfs-hpc/rc/home/t/f00355t/imbalance')\n",
    "from imblearn.over_sampling import SMOTE\n",
    "np.set_printoptions(threshold='nan')\n",
    "tmp = np.loadtxt(\"AID688.csv\", dtype=np.str,skiprows=1, delimiter=\",\")\n",
    "total_data=tmp[0:,0:tmp.shape[1]-2].astype(np.float)\n",
    "total_label=tmp[0:,tmp.shape[1]-1].astype(np.float)\n",
    "\n",
    "import random\n",
    "import math\n",
    "def randomly_pos_points_pick(training_data, training_label, pos_points_ratio_power):\n",
    "    positive_points_index_set = np.where(training_label==1)[0]\n",
    "    num_to_pick = int(math.pow(10, pos_points_ratio_power) * len(training_label))\n",
    "    # Need at least two pos points to apply SMOTE\n",
    "    if num_to_pick < 2:\n",
    "        num_to_pick = 2\n",
    "    random.seed(0)\n",
    "    # Use random.sample to pick up positive points randomly\n",
    "    random_index_set = random.sample(list(positive_points_index_set), num_to_pick)\n",
    "    # Use the index to filter out original training data and training label\n",
    "    print random_index_set\n",
    "    zero_data=training_data[np.where(training_label==0)[0]]\n",
    "    zero_label=training_label[np.where(training_label==0)[0]]\n",
    "    training_data_after_sampling = training_data[random_index_set]\n",
    "    training_label_after_sampling = training_label[random_index_set]\n",
    "    training_data_after_sampling=np.concatenate((zero_data, training_data_after_sampling), axis=0)\n",
    "    training_label_after_sampling = np.concatenate((zero_label, training_label_after_sampling), axis=0)\n",
    "    return training_data_after_sampling, training_label_after_sampling\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "kfold = skf.split(total_data, total_label)\n",
    "K = -1\n",
    "svm_matrix = np.zeros((10, 2, 2))\n",
    "svm_auc = np.zeros((10, 1, 1))\n",
    "svm_recall = np.zeros((10, 1, 1))\n",
    "svm_p = np.zeros((10, 1, 1))\n",
    "svm_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "bn_matrix = np.zeros((10, 2, 2))\n",
    "bn_auc = np.zeros((10, 1, 1))\n",
    "bn_recall = np.zeros((10, 1, 1))\n",
    "bn_p = np.zeros((10, 1, 1))\n",
    "bn_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "\n",
    "randomforest_matrix = np.zeros((10, 2, 2))\n",
    "randomforest_auc = np.zeros((10, 1, 1))\n",
    "randomforest_recall = np.zeros((10, 1, 1))\n",
    "randomforest_p = np.zeros((10, 1, 1))\n",
    "randomforest_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "knn_matrix = np.zeros((10, 2, 2))\n",
    "knn_auc = np.zeros((10, 1, 1))\n",
    "knn_recall = np.zeros((10, 1, 1))\n",
    "knn_p = np.zeros((10, 1, 1))\n",
    "knn_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "lr_matrix = np.zeros((10, 2, 2))\n",
    "lr_auc = np.zeros((10, 1, 1))\n",
    "lr_recall = np.zeros((10, 1, 1))\n",
    "lr_p = np.zeros((10, 1, 1))\n",
    "lr_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "gb_matrix = np.zeros((10, 2, 2))\n",
    "gb_auc = np.zeros((10, 1, 1))\n",
    "gb_recall = np.zeros((10, 1, 1))\n",
    "gb_p = np.zeros((10, 1, 1))\n",
    "gb_F1 = np.zeros((10, 1, 1))\n",
    "c_matrix=np.zeros((2,2))\n",
    "c_matrix[1][1]=0.001\n",
    "c_matrix[0][0]=0.001\n",
    "c_matrix[1][0]=0.001\n",
    "c_matrix[0][1]=0.001\n",
    "for traini, testi in kfold:\n",
    "\tK = K + 1\n",
    "\tdata_train, data_test = total_data[traini], total_data[testi]\n",
    "\tlabel_train, label_test = total_label[traini], total_label[testi]\n",
    "\tsm = SMOTE(random_state=1)\n",
    "\tdata_train, label_train = sm.fit_sample(data_train, label_train)\n",
    "\tline = data_train.size / data_train[0].size\n",
    "\n",
    "    #data_train, label2 = shuffle(data_train, label2, random_state=830)\n",
    "\n",
    "\n",
    "\tbn = BernoulliNB()\n",
    "\tpredict_label =bn.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=bn.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tbn_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tbn_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tbn_F1[K]=2*(bn_recall[K]*bn_p[K])/(bn_recall[K]+bn_p[K])\n",
    "\tbn_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(bn_F1[K])):\n",
    "\t\tbn_F1[K] = 0\n",
    "\n",
    "\n",
    "\tknn2 = KNeighborsClassifier()\n",
    "\tpredict_label =knn2.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=knn2.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tknn_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tknn_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tknn_F1[K]=2*(knn_recall[K]*knn_p[K])/(knn_recall[K]+knn_p[K])\n",
    "\tknn_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(knn_F1[K])):\n",
    "\t\tknn_F1[K] = 0\n",
    "\n",
    "\n",
    "\tlr2 = LogisticRegression()\n",
    "\tpredict_label =lr2.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=lr2.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tlr_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tlr_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tlr_F1[K]=2*(lr_recall[K]*lr_p[K])/(lr_recall[K]+lr_p[K])\n",
    "\tlr_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(lr_F1[K])):\n",
    "\t\tlr_F1[K] = 0\n",
    "\n",
    "\tgb = GaussianNB()\n",
    "\tpredict_label =gb.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=gb.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tgb_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tgb_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tgb_F1[K]=2*(gb_recall[K]*gb_p[K])/(gb_recall[K]+gb_p[K])\n",
    "\tgb_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(gb_F1[K])):\n",
    "\t\tgb_F1[K] = 0\n",
    "\t\n",
    "\n",
    "\trandomforest = RandomForestClassifier()\n",
    "\tpredict_label = randomforest.fit(data_train, label_train).predict(data_test)\n",
    "\tdf = randomforest.predict_proba(data_test)[:, 1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\trandomforest_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\trandomforest_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\trandomforest_F1[K]=2*(randomforest_recall[K]*randomforest_p[K])/(randomforest_recall[K]+randomforest_p[K])\n",
    "\trandomforest_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(randomforest_F1[K])):\n",
    "\t\trandomforest_F1[K] = 0\n",
    "\n",
    "print \"----------------------Finally-------------------------\"\n",
    "\n",
    "\n",
    "print \"bn\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(bn_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(bn_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(bn_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(bn_F1))\n",
    "\n",
    "print \"knn\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(knn_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(knn_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(knn_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(knn_F1))\n",
    "\n",
    "print \"lr\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(lr_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(lr_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(lr_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(lr_F1))\n",
    "\n",
    "print \"gb\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(gb_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(gb_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(gb_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(gb_F1))\n",
    "\n",
    "print \"randomforest\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(randomforest_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(randomforest_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(randomforest_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(randomforest_F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AID373 daset with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:133: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:145: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:156: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:167: RuntimeWarning: invalid value encountered in divide\n",
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:168: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Finally-------------------------\n",
      "bn\n",
      "The AUC is 0.609 \n",
      "The recall is 0.250 \n",
      "The p is 0.001 \n",
      "The F1 is 0.002 \n",
      "knn\n",
      "The AUC is 0.590 \n",
      "The recall is 0.200 \n",
      "The p is 0.002 \n",
      "The F1 is 0.004 \n",
      "lr\n",
      "The AUC is 0.713 \n",
      "The recall is 0.200 \n",
      "The p is 0.003 \n",
      "The F1 is 0.005 \n",
      "gb\n",
      "The AUC is 0.459 \n",
      "The recall is 0.400 \n",
      "The p is 0.000 \n",
      "The F1 is 0.000 \n",
      "randomforest\n",
      "The AUC is 0.648 \n",
      "The recall is 0.100 \n",
      "The p is nan \n",
      "The F1 is 0.100 \n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import numpy as np  \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.metrics import silhouette_score\n",
    "import sys\n",
    "sys.path.append('/dartfs-hpc/rc/home/t/f00355t/imbalance')\n",
    "from imblearn.over_sampling import SMOTE\n",
    "np.set_printoptions(threshold='nan')\n",
    "tmp = np.loadtxt(\"AID373.csv\", dtype=np.str,skiprows=1, delimiter=\",\")\n",
    "total_data=tmp[0:,0:tmp.shape[1]-2].astype(np.float)\n",
    "total_label=tmp[0:,tmp.shape[1]-1].astype(np.float)\n",
    "\n",
    "import random\n",
    "import math\n",
    "def randomly_pos_points_pick(training_data, training_label, pos_points_ratio_power):\n",
    "    positive_points_index_set = np.where(training_label==1)[0]\n",
    "    num_to_pick = int(math.pow(10, pos_points_ratio_power) * len(training_label))\n",
    "    # Need at least two pos points to apply SMOTE\n",
    "    if num_to_pick < 2:\n",
    "        num_to_pick = 2\n",
    "    random.seed(0)\n",
    "    # Use random.sample to pick up positive points randomly\n",
    "    random_index_set = random.sample(list(positive_points_index_set), num_to_pick)\n",
    "    # Use the index to filter out original training data and training label\n",
    "    print random_index_set\n",
    "    zero_data=training_data[np.where(training_label==0)[0]]\n",
    "    zero_label=training_label[np.where(training_label==0)[0]]\n",
    "    training_data_after_sampling = training_data[random_index_set]\n",
    "    training_label_after_sampling = training_label[random_index_set]\n",
    "    training_data_after_sampling=np.concatenate((zero_data, training_data_after_sampling), axis=0)\n",
    "    training_label_after_sampling = np.concatenate((zero_label, training_label_after_sampling), axis=0)\n",
    "    return training_data_after_sampling, training_label_after_sampling\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "kfold = skf.split(total_data, total_label)\n",
    "K = -1\n",
    "svm_matrix = np.zeros((10, 2, 2))\n",
    "svm_auc = np.zeros((10, 1, 1))\n",
    "svm_recall = np.zeros((10, 1, 1))\n",
    "svm_p = np.zeros((10, 1, 1))\n",
    "svm_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "bn_matrix = np.zeros((10, 2, 2))\n",
    "bn_auc = np.zeros((10, 1, 1))\n",
    "bn_recall = np.zeros((10, 1, 1))\n",
    "bn_p = np.zeros((10, 1, 1))\n",
    "bn_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "\n",
    "randomforest_matrix = np.zeros((10, 2, 2))\n",
    "randomforest_auc = np.zeros((10, 1, 1))\n",
    "randomforest_recall = np.zeros((10, 1, 1))\n",
    "randomforest_p = np.zeros((10, 1, 1))\n",
    "randomforest_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "knn_matrix = np.zeros((10, 2, 2))\n",
    "knn_auc = np.zeros((10, 1, 1))\n",
    "knn_recall = np.zeros((10, 1, 1))\n",
    "knn_p = np.zeros((10, 1, 1))\n",
    "knn_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "lr_matrix = np.zeros((10, 2, 2))\n",
    "lr_auc = np.zeros((10, 1, 1))\n",
    "lr_recall = np.zeros((10, 1, 1))\n",
    "lr_p = np.zeros((10, 1, 1))\n",
    "lr_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "gb_matrix = np.zeros((10, 2, 2))\n",
    "gb_auc = np.zeros((10, 1, 1))\n",
    "gb_recall = np.zeros((10, 1, 1))\n",
    "gb_p = np.zeros((10, 1, 1))\n",
    "gb_F1 = np.zeros((10, 1, 1))\n",
    "c_matrix=np.zeros((2,2))\n",
    "c_matrix[1][1]=0.001\n",
    "c_matrix[0][0]=0.001\n",
    "c_matrix[1][0]=0.001\n",
    "c_matrix[0][1]=0.001\n",
    "for traini, testi in kfold:\n",
    "\tK = K + 1\n",
    "\tdata_train, data_test = total_data[traini], total_data[testi]\n",
    "\tlabel_train, label_test = total_label[traini], total_label[testi]\n",
    "\tsm = SMOTE(random_state=1)\n",
    "\tdata_train, label_train = sm.fit_sample(data_train, label_train)\n",
    "\tline = data_train.size / data_train[0].size\n",
    "\n",
    "    #data_train, label2 = shuffle(data_train, label2, random_state=830)\n",
    "\n",
    "\n",
    "\tbn = BernoulliNB()\n",
    "\tpredict_label =bn.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=bn.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tbn_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tbn_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tbn_F1[K]=2*(bn_recall[K]*bn_p[K])/(bn_recall[K]+bn_p[K])\n",
    "\tbn_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(bn_F1[K])):\n",
    "\t\tbn_F1[K] = 0\n",
    "\n",
    "\n",
    "\tknn2 = KNeighborsClassifier()\n",
    "\tpredict_label =knn2.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=knn2.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tknn_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tknn_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tknn_F1[K]=2*(knn_recall[K]*knn_p[K])/(knn_recall[K]+knn_p[K])\n",
    "\tknn_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(knn_F1[K])):\n",
    "\t\tknn_F1[K] = 0\n",
    "\n",
    "\n",
    "\tlr2 = LogisticRegression()\n",
    "\tpredict_label =lr2.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=lr2.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tlr_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tlr_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tlr_F1[K]=2*(lr_recall[K]*lr_p[K])/(lr_recall[K]+lr_p[K])\n",
    "\tlr_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(lr_F1[K])):\n",
    "\t\tlr_F1[K] = 0\n",
    "\n",
    "\tgb = GaussianNB()\n",
    "\tpredict_label =gb.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=gb.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tgb_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tgb_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tgb_F1[K]=2*(gb_recall[K]*gb_p[K])/(gb_recall[K]+gb_p[K])\n",
    "\tgb_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(gb_F1[K])):\n",
    "\t\tgb_F1[K] = 0\n",
    "\t\n",
    "\n",
    "\trandomforest = RandomForestClassifier()\n",
    "\tpredict_label = randomforest.fit(data_train, label_train).predict(data_test)\n",
    "\tdf = randomforest.predict_proba(data_test)[:, 1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\trandomforest_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\trandomforest_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\trandomforest_F1[K]=2*(randomforest_recall[K]*randomforest_p[K])/(randomforest_recall[K]+randomforest_p[K])\n",
    "\trandomforest_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(randomforest_F1[K])):\n",
    "\t\trandomforest_F1[K] = 0\n",
    "\n",
    "print \"----------------------Finally-------------------------\"\n",
    "\n",
    "\n",
    "print \"bn\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(bn_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(bn_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(bn_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(bn_F1))\n",
    "\n",
    "print \"knn\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(knn_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(knn_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(knn_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(knn_F1))\n",
    "\n",
    "print \"lr\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(lr_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(lr_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(lr_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(lr_F1))\n",
    "\n",
    "print \"gb\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(gb_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(gb_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(gb_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(gb_F1))\n",
    "\n",
    "print \"randomforest\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(randomforest_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(randomforest_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(randomforest_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(randomforest_F1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AID604 daset with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python27\\lib\\site-packages\\ipykernel_launcher.py:168: RuntimeWarning: invalid value encountered in divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Finally-------------------------\n",
      "bn\n",
      "The AUC is 0.636 \n",
      "The recall is 0.250 \n",
      "The p is 0.005 \n",
      "The F1 is 0.009 \n",
      "knn\n",
      "The AUC is 0.586 \n",
      "The recall is 0.282 \n",
      "The p is 0.008 \n",
      "The F1 is 0.015 \n",
      "lr\n",
      "The AUC is 0.788 \n",
      "The recall is 0.665 \n",
      "The p is 0.011 \n",
      "The F1 is 0.022 \n",
      "gb\n",
      "The AUC is 0.572 \n",
      "The recall is 0.920 \n",
      "The p is 0.004 \n",
      "The F1 is 0.008 \n",
      "randomforest\n",
      "The AUC is 0.684 \n",
      "The recall is 0.052 \n",
      "The p is 0.295 \n",
      "The F1 is 0.084 \n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import numpy as np  \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import cross_validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.metrics import silhouette_score\n",
    "import sys\n",
    "sys.path.append('/dartfs-hpc/rc/home/t/f00355t/imbalance')\n",
    "from imblearn.over_sampling import SMOTE\n",
    "np.set_printoptions(threshold='nan')\n",
    "tmp = np.loadtxt(\"AID604.csv\", dtype=np.str,skiprows=1, delimiter=\",\")\n",
    "total_data=tmp[0:,0:tmp.shape[1]-2].astype(np.float)\n",
    "total_label=tmp[0:,tmp.shape[1]-1].astype(np.float)\n",
    "\n",
    "import random\n",
    "import math\n",
    "def randomly_pos_points_pick(training_data, training_label, pos_points_ratio_power):\n",
    "    positive_points_index_set = np.where(training_label==1)[0]\n",
    "    num_to_pick = int(math.pow(10, pos_points_ratio_power) * len(training_label))\n",
    "    # Need at least two pos points to apply SMOTE\n",
    "    if num_to_pick < 2:\n",
    "        num_to_pick = 2\n",
    "    random.seed(0)\n",
    "    # Use random.sample to pick up positive points randomly\n",
    "    random_index_set = random.sample(list(positive_points_index_set), num_to_pick)\n",
    "    # Use the index to filter out original training data and training label\n",
    "    print random_index_set\n",
    "    zero_data=training_data[np.where(training_label==0)[0]]\n",
    "    zero_label=training_label[np.where(training_label==0)[0]]\n",
    "    training_data_after_sampling = training_data[random_index_set]\n",
    "    training_label_after_sampling = training_label[random_index_set]\n",
    "    training_data_after_sampling=np.concatenate((zero_data, training_data_after_sampling), axis=0)\n",
    "    training_label_after_sampling = np.concatenate((zero_label, training_label_after_sampling), axis=0)\n",
    "    return training_data_after_sampling, training_label_after_sampling\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "kfold = skf.split(total_data, total_label)\n",
    "K = -1\n",
    "svm_matrix = np.zeros((10, 2, 2))\n",
    "svm_auc = np.zeros((10, 1, 1))\n",
    "svm_recall = np.zeros((10, 1, 1))\n",
    "svm_p = np.zeros((10, 1, 1))\n",
    "svm_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "bn_matrix = np.zeros((10, 2, 2))\n",
    "bn_auc = np.zeros((10, 1, 1))\n",
    "bn_recall = np.zeros((10, 1, 1))\n",
    "bn_p = np.zeros((10, 1, 1))\n",
    "bn_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "\n",
    "randomforest_matrix = np.zeros((10, 2, 2))\n",
    "randomforest_auc = np.zeros((10, 1, 1))\n",
    "randomforest_recall = np.zeros((10, 1, 1))\n",
    "randomforest_p = np.zeros((10, 1, 1))\n",
    "randomforest_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "knn_matrix = np.zeros((10, 2, 2))\n",
    "knn_auc = np.zeros((10, 1, 1))\n",
    "knn_recall = np.zeros((10, 1, 1))\n",
    "knn_p = np.zeros((10, 1, 1))\n",
    "knn_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "lr_matrix = np.zeros((10, 2, 2))\n",
    "lr_auc = np.zeros((10, 1, 1))\n",
    "lr_recall = np.zeros((10, 1, 1))\n",
    "lr_p = np.zeros((10, 1, 1))\n",
    "lr_F1 = np.zeros((10, 1, 1))\n",
    "\n",
    "gb_matrix = np.zeros((10, 2, 2))\n",
    "gb_auc = np.zeros((10, 1, 1))\n",
    "gb_recall = np.zeros((10, 1, 1))\n",
    "gb_p = np.zeros((10, 1, 1))\n",
    "gb_F1 = np.zeros((10, 1, 1))\n",
    "c_matrix=np.zeros((2,2))\n",
    "c_matrix[1][1]=0.001\n",
    "c_matrix[0][0]=0.001\n",
    "c_matrix[1][0]=0.001\n",
    "c_matrix[0][1]=0.001\n",
    "for traini, testi in kfold:\n",
    "\tK = K + 1\n",
    "\tdata_train, data_test = total_data[traini], total_data[testi]\n",
    "\tlabel_train, label_test = total_label[traini], total_label[testi]\n",
    "\tsm = SMOTE(random_state=1)\n",
    "\tdata_train, label_train = sm.fit_sample(data_train, label_train)\n",
    "\tline = data_train.size / data_train[0].size\n",
    "\n",
    "    #data_train, label2 = shuffle(data_train, label2, random_state=830)\n",
    "\n",
    "\n",
    "\tbn = BernoulliNB()\n",
    "\tpredict_label =bn.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=bn.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tbn_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tbn_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tbn_F1[K]=2*(bn_recall[K]*bn_p[K])/(bn_recall[K]+bn_p[K])\n",
    "\tbn_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(bn_F1[K])):\n",
    "\t\tbn_F1[K] = 0\n",
    "\n",
    "\n",
    "\tknn2 = KNeighborsClassifier()\n",
    "\tpredict_label =knn2.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=knn2.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tknn_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tknn_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tknn_F1[K]=2*(knn_recall[K]*knn_p[K])/(knn_recall[K]+knn_p[K])\n",
    "\tknn_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(knn_F1[K])):\n",
    "\t\tknn_F1[K] = 0\n",
    "\n",
    "\n",
    "\tlr2 = LogisticRegression()\n",
    "\tpredict_label =lr2.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=lr2.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tlr_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tlr_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tlr_F1[K]=2*(lr_recall[K]*lr_p[K])/(lr_recall[K]+lr_p[K])\n",
    "\tlr_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(lr_F1[K])):\n",
    "\t\tlr_F1[K] = 0\n",
    "\n",
    "\tgb = GaussianNB()\n",
    "\tpredict_label =gb.fit(data_train, label_train).predict(data_test)\n",
    "\tdf=gb.predict_proba(data_test)[:,1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\tgb_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\tgb_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\tgb_F1[K]=2*(gb_recall[K]*gb_p[K])/(gb_recall[K]+gb_p[K])\n",
    "\tgb_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(gb_F1[K])):\n",
    "\t\tgb_F1[K] = 0\n",
    "\t\n",
    "\n",
    "\trandomforest = RandomForestClassifier()\n",
    "\tpredict_label = randomforest.fit(data_train, label_train).predict(data_test)\n",
    "\tdf = randomforest.predict_proba(data_test)[:, 1]\n",
    "\tc_matrix= confusion_matrix(label_test, predict_label)\n",
    "\trandomforest_recall[K]=c_matrix[1,1]/(c_matrix[1,0]+c_matrix[1,1]+0.0)\n",
    "\trandomforest_p[K]=c_matrix[1,1]/(c_matrix[0,1]+c_matrix[1,1]+0.0)\n",
    "\trandomforest_F1[K]=2*(randomforest_recall[K]*randomforest_p[K])/(randomforest_recall[K]+randomforest_p[K])\n",
    "\trandomforest_auc[K]=roc_auc_score(label_test, df)\n",
    "\tif (np.isnan(randomforest_F1[K])):\n",
    "\t\trandomforest_F1[K] = 0\n",
    "\n",
    "print \"----------------------Finally-------------------------\"\n",
    "\n",
    "\n",
    "print \"bn\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(bn_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(bn_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(bn_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(bn_F1))\n",
    "\n",
    "print \"knn\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(knn_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(knn_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(knn_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(knn_F1))\n",
    "\n",
    "print \"lr\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(lr_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(lr_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(lr_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(lr_F1))\n",
    "\n",
    "print \"gb\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(gb_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(gb_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(gb_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(gb_F1))\n",
    "\n",
    "print \"randomforest\"\n",
    "print \"The AUC is %0.3f \" % (np.mean(randomforest_auc))\n",
    "print \"The recall is %0.3f \" % (np.mean(randomforest_recall))\n",
    "print \"The p is %0.3f \" % (np.mean(randomforest_p))\n",
    "print \"The F1 is %0.3f \" % (np.mean(randomforest_F1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
